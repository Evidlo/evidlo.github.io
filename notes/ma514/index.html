<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="stylesheet" type="text/css" href="/fancy.css"/>
  <link rel="stylesheet" type="text/css" href="/notes.css"/>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Evan Widloski</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script>
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-25109327-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
    <style type="text/css">
  a.sourceLine { display: inline-block; line-height: 1.25; }
  a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
  a.sourceLine:empty { height: 1.2em; position: absolute; }
  .sourceCode { overflow: visible; }
  code.sourceCode { white-space: pre; position: relative; }
  div.sourceCode { margin: 1em 0; }
  pre.sourceCode { margin: 0; }
  @media screen {
  div.sourceCode { overflow: auto; }
  }
  @media print {
  code.sourceCode { white-space: pre-wrap; }
  a.sourceLine { text-indent: -1em; padding-left: 1em; }
  }
  pre.numberSource a.sourceLine
    { position: relative; }
  pre.numberSource a.sourceLine:empty
    { position: absolute; }
  pre.numberSource a.sourceLine::before
    { content: attr(data-line-number);
      position: absolute; left: -5em; text-align: right; vertical-align: baseline;
      border: none; pointer-events: all;
      -webkit-touch-callout: none; -webkit-user-select: none;
      -khtml-user-select: none; -moz-user-select: none;
      -ms-user-select: none; user-select: none;
      padding: 0 4px; width: 4em;
      color: #aaaaaa;
    }
  pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
  div.sourceCode
    {  }
  @media screen {
  a.sourceLine::before { text-decoration: underline; }
  }
  code span.al { color: #ff0000; font-weight: bold; } /* Alert */
  code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
  code span.at { color: #7d9029; } /* Attribute */
  code span.bn { color: #40a070; } /* BaseN */
  code span.bu { } /* BuiltIn */
  code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
  code span.ch { color: #4070a0; } /* Char */
  code span.cn { color: #880000; } /* Constant */
  code span.co { color: #60a0b0; font-style: italic; } /* Comment */
  code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
  code span.do { color: #ba2121; font-style: italic; } /* Documentation */
  code span.dt { color: #902000; } /* DataType */
  code span.dv { color: #40a070; } /* DecVal */
  code span.er { color: #ff0000; font-weight: bold; } /* Error */
  code span.ex { } /* Extension */
  code span.fl { color: #40a070; } /* Float */
  code span.fu { color: #06287e; } /* Function */
  code span.im { } /* Import */
  code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  code span.kw { color: #007020; font-weight: bold; } /* Keyword */
  code span.op { color: #666666; } /* Operator */
  code span.ot { color: #007020; } /* Other */
  code span.pp { color: #bc7a00; } /* Preprocessor */
  code span.sc { color: #4070a0; } /* SpecialChar */
  code span.ss { color: #bb6688; } /* SpecialString */
  code span.st { color: #4070a0; } /* String */
  code span.va { color: #19177c; } /* Variable */
  code span.vs { color: #4070a0; } /* VerbatimString */
  code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  
  
  <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    displayAlign: "left",
    displayIndent: "0em"
  });
  </script>

  <script>
    function showHide(e) {
    latexblock = $(e).find('.latex');
    if (latexblock.hasClass('opened')) {
        // close block
        latexblock.removeClass('opened');
        latexblock.hide();
    } else {
        // open block
        latexblock.addClass('opened');
        latexblock.show();
    }
  }
  </script>

  </head>

<body>
	<div class="v h">
		<div class="h hc">
			<div class="simplebox">
				<div class="title">MA514 - Numerical Analysis - Spring 2017</div>
				<div class="body v">
                    <ul>
          <li><a href="#floating-point-arithmetic">Floating Point Arithmetic</a><ul>
          <li><a href="#double-precision-floating-point">Double Precision Floating Point</a><ul>
          <li><a href="#special-numbers">Special Numbers</a></li>
          <li><a href="#subnormal-numbers">Subnormal numbers</a></li>
          <li><a href="#error">Error</a></li>
          </ul></li>
          <li><a href="#arithmetic-operations">Arithmetic Operations</a><ul>
          <li><a href="#multiplication">Multiplication</a></li>
          <li><a href="#addition">Addition</a></li>
          <li><a href="#subtraction">Subtraction</a></li>
          </ul></li>
          </ul></li>
          <li><a href="#condition-of-a-problem">Condition of a problem</a></li>
          <li><a href="#stability-of-an-algorithm">Stability of an Algorithm</a></li>
          <li><a href="#finding-roots">Finding Roots</a><ul>
          <li><a href="#intermediate-value-theorem">Intermediate Value Theorem</a></li>
          <li><a href="#secant-method">Secant Method</a><ul>
          <li><a href="#convergence">Convergence</a></li>
          </ul></li>
          <li><a href="#newtons-method">Newton's Method</a><ul>
          <li><a href="#convergence-1">Convergence</a></li>
          </ul></li>
          <li><a href="#bisection-method">Bisection Method</a><ul>
          <li><a href="#convergence-2">Convergence</a></li>
          </ul></li>
          <li><a href="#fixed-point-iteration">Fixed point iteration</a><ul>
          <li><a href="#uniqueness">Uniqueness</a></li>
          <li><a href="#convergence-3">Convergence</a></li>
          </ul></li>
          <li><a href="#implementation">Implementation</a></li>
          <li><a href="#condition-number">Condition Number</a></li>
          <li><a href="#matrices">Matrices</a></li>
          </ul></li>
          <li><a href="#finding-minimums">Finding Minimums</a><ul>
          <li><a href="#implementation-1">Implementation</a><ul>
          <li><a href="#golden-section-search">Golden Section Search</a></li>
          <li><a href="#parabolic-interpolation">Parabolic Interpolation</a></li>
          <li><a href="#solving-for-minimum-of-parabola">Solving for minimum of parabola</a></li>
          </ul></li>
          </ul></li>
          <li><a href="#interpolation">Interpolation</a><ul>
          <li><a href="#power-basis">Power basis</a></li>
          <li><a href="#general-matrix-form">General matrix form</a></li>
          <li><a href="#lagrange-basis">Lagrange basis</a></li>
          </ul></li>
          <li><a href="#newton-form-interpolating-polynomial">Newton Form Interpolating Polynomial</a><ul>
          <li><a href="#divided-difference">Divided difference</a></li>
          <li><a href="#interpolation-with-derivatives">Interpolation with Derivatives</a></li>
          <li><a href="#error-1">Error</a></li>
          <li><a href="#horners-method">Horner's Method</a></li>
          </ul></li>
          <li><a href="#chebyshev-interpolating-points.">Chebyshev Interpolating points.</a></li>
          <li><a href="#piecewise-interpolation">Piecewise Interpolation</a><ul>
          <li><a href="#hermite-interpolation">Hermite Interpolation</a></li>
          </ul></li>
          <li><a href="#numerical-integration">Numerical Integration</a></li>
          <li><a href="#midpoint-method">Midpoint Method</a><ul>
          <li><a href="#error-2">Error</a><ul>
          <li><a href="#mvt-for-integrals">MVT for Integrals</a></li>
          </ul></li>
          </ul></li>
          <li><a href="#trapezoidal-method">Trapezoidal Method</a><ul>
          <li><a href="#error-3">Error</a></li>
          </ul></li>
          <li><a href="#simpsons-method">Simpson's Method</a><ul>
          <li><a href="#error-4">Error</a></li>
          </ul></li>
          <li><a href="#degree-of-precision">Degree of Precision</a></li>
          <li><a href="#composite-midpoint-rule">Composite Midpoint Rule</a></li>
          <li><a href="#composite-trapezoidal-rule">Composite Trapezoidal Rule</a></li>
          <li><a href="#composite-simpsons-rule">Composite Simpson's Rule</a></li>
          <li><a href="#gaussian-quadrature">Gaussian Quadrature</a></li>
          <li><a href="#approximating-functions">Approximating Functions</a><ul>
          <li><a href="#properties-of-norms">Properties of Norms</a></li>
          <li><a href="#least-squares">Least Squares</a></li>
          <li><a href="#chebyshev-polynomial">Chebyshev Polynomial</a><ul>
          <li><a href="#alternative-representation">Alternative Representation</a></li>
          </ul></li>
          </ul></li>
          <li><a href="#todo">todo</a></li>
          </ul>
                    <ul>
<li>ascher and greif, a first course in numerical methods</li>
</ul>
<h1 id="floating-point-arithmetic">Floating Point Arithmetic</h1>
<div class="definition">
<p>Denoted as <span class="math inline">\(fl(x)\)</span> <span class="math inline">\(fl(x) = -1 (1 d_1 d_2 d_3 ...)_2 \cdot 2^{exp}\)</span> sign bit - binary fraction - exponent</p>
<p>When a number is normalized, 1 is added to the binary fraction: <span class="math inline">\(fl(x) = (-1)^{d_s} (1 + d_1 d_2 d_3 ... d_n)_2 \cdot 2^{exp}\)</span></p>
</div>
<div class="examples">
<p>Let <span class="math inline">\(t = 2\)</span> be the number of digits, <span class="math inline">\([L, U] = [-2, 1]\)</span> be the range of possible exponents.</p>
<p>What are the possible values that can be stored in our floating point system?</p>
<p><strong>Binary fractions</strong></p>
<ul>
<li>1.00 = 1</li>
<li>1.01 = 1 + 1/4 = 5/4</li>
<li>1.10 = 1 + 1/2 = 3/2</li>
<li>1.11 = 1 + 1/2 + 1/4 = 7/4</li>
</ul>
<p>*When exponentiated*</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(2^{-2}\)</span></th>
<th><span class="math inline">\(2^{-1}\)</span></th>
<th><span class="math inline">\(2^{0}\)</span></th>
<th><span class="math inline">\(2^{1}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1/4</td>
<td>1/2</td>
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td>5/16</td>
<td>5/8</td>
<td>5/4</td>
<td>5/2</td>
</tr>
<tr class="odd">
<td>3/8</td>
<td>3/4</td>
<td>3/2</td>
<td>3</td>
</tr>
<tr class="even">
<td>7/16</td>
<td>7/8</td>
<td>7/4</td>
<td>7/2</td>
</tr>
</tbody>
</table>
</div>
<div class="theorem">
<ul>
<li>Floating point systems can represent a finite number of values.</li>
<li>Floating point systems have a minimum and maximum, denoted as <span class="math inline">\(realmin\)</span> and <span class="math inline">\(realmax\)</span>.</li>
<li>The spacing between consecutive numbers increases as the magnitude of the number increases.</li>
<li>The spacing between 0 and <span class="math inline">\(realmin\)</span> is larger than the space between <span class="math inline">\(realmin\)</span> and the next number.</li>
</ul>
</div>
<h2 id="double-precision-floating-point">Double Precision Floating Point</h2>
<p><strong>binary64</strong> - specified by IEEE 754</p>
<ul>
<li>1 sign bit</li>
<li>11 exponent bits</li>
<li><p>52 fraction bits</p>
<p>64 bits total</p>
<p><span class="math inline">\(fl(x) = (-1)^{d_s}(1 + d_1 d_2 ... d_52) \cdot 2^{exp - 1023}\)</span></p>
<p>This shifted exponent is known as a <strong>biased</strong> exponent and gives us a range of exponents <span class="math inline">\([-1023, 1024]\)</span>. However, we reserve -1023 and 1024 to represent NaN and Inf, respectively.</p>
<p><span class="math inline">\(realmin = (1.0000...0) \cdot 2^{-1022}\)</span> <span class="math inline">\(realmax = (1.1111...1) \cdot 2^{1023}\)</span></p></li>
</ul>
<h3 id="special-numbers">Special Numbers</h3>
<ul>
<li><span class="math inline">\(0(0...0)_2 \cdot 2^{1...1} = +Inf\)</span></li>
<li><span class="math inline">\(1(0...0)_2 \cdot 2^{1...1} = -Inf\)</span></li>
<li><span class="math inline">\(0(\neq 0)_2 \cdot 2^{1...1} = +NaN\)</span></li>
<li><span class="math inline">\(1(\neq 0)_2 \cdot 2^{1...1} = -NaN\)</span></li>
<li><span class="math inline">\(0(0...0)_2 \cdot 2^{0...0} = +0\)</span></li>
<li><span class="math inline">\(1(0...0)_2 \cdot 2^{0...0} = -0\)</span></li>
</ul>
<p>#+end<sub>examples</sub></p>
<div class="examples">
<ol>
<li>Find the value of <span class="math inline">\((7ff0\ 0000\ 0000\ 0000)_{16}\)</span> 0111 1111 1111 0… = +Inf</li>
<li>Find the value of <span class="math inline">\((4014\ 0000\ 0000\ 0000)_{16} = 0100\ 0000\ 0001\ 0100\ 0\dots\)</span> <span class="math inline">\(\underbrace{0}_\text{sign bit}\underbrace{100\ 0000\ 0001}_\text{exp}\ \underbrace{0100\ 0...}_\text{frac} = (1+2^{-2}) \cdot 2^{1025 - 1023} = 5\)</span></li>
</ol>
</div>
<h3 id="subnormal-numbers">Subnormal numbers</h3>
<p><span class="math inline">\(fl(x) = (-1)^{d_s} (0 + d_1 d_2 d_3 ... d_n)_2 \cdot 2^{exp}\)</span></p>
<ul>
<li><span class="math inline">\(0(\neq = 0)_2 \cdot 2^{0...0} = subnormal\)</span></li>
</ul>
<p>Smallest exp - -1074 Largest exp - 1023</p>
<h3 id="error">Error</h3>
<div class="definition">
<p><strong>Relative error</strong></p>
<p><span class="math inline">\(\frac{|x - f(x)|}{|x|}\)</span></p>
<p>In floating point, the relative error is bounded by a constant <span class="math inline">\(\eta\)</span>, which is given by</p>
<p><span class="math display">\[\eta = \begin{cases}
2^{-t} &amp; \text{if truncated} \\ 
2^{-(t+1)} &amp; \text{if rounded} 
\end{cases}\]</span></p>
<p>where <span class="math inline">\(t\)</span> is the number of bits truncated or rounded to.</p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Derivation
</div>
<div class="derivation latex" style="display:none;">

<p><strong>truncation</strong> truncation: <span class="math inline">\((1.d_1\ d_2\cdots \d_t) \cdot 2^{exp}\)</span></p>
<p><span class="math inline">\(|x - f(x)| \leq (0.0 \cdots 1) \cdot 2^{exp}
\leq 2^{-t} \cdot 2^{exp}\)</span> <span class="math inline">\(|x - f(x)| \leq \frac{2^{-t} 2^{exp}}{(1.0 \cdots 0)_2 \cdot 2^{exp}} = 2^{-t}\)</span></p>
<p><strong>rounding</strong> truncation: <span class="math inline">\((1.d_1\ d_2\cdots {d_t}{\text{+2{-t} if d_{t+1} = 1}) \cdot 2^{exp}\)</span> <span class="math inline">\(|x - f(x)| \leq (0.0 \cdots 2^{-1(t+1)}) \cdot 2^{exp}
\leq 2^{-t} \cdot 2^{exp}\)</span> <span class="math inline">\(|x - f(x)| \leq \frac{2^{-(t+1)} 2^{exp}}{(1.0 \cdots 0)_2 \cdot 2^{exp}} = 2^{-(t+1)}\)</span></p>

</div>
</div>

<p>In Octave, <strong>exp()</strong> gives the distance between a number and the next smallest floating point number.</p>
<div class="examples">
<ol>
<li>x = 1 exp(1) = (1.0 ⋯ 1)<sub>2</sub> ⋅ 2<sup>0</sup> = 2<sup>-52</sup></li>
</ol>
</div>
<h2 id="arithmetic-operations">Arithmetic Operations</h2>
<p>Let <span class="math inline">\(x,y \in \mathbb{R}\)</span></p>
<h3 id="multiplication">Multiplication</h3>
<p><span class="math inline">\(f(x)\)</span> can be expressed as <span class="math inline">\(x(1 + \delta)\)</span> where <span class="math inline">\(|\delta| \leq \eta\)</span></p>
<p><span class="math inline">\(f(x \cdot y) = (x(1 + \delta_x) \cdot y(1 + \delta_y)){(1 + \delta_m)}{rounding after multiplication}\)</span> = xy(1 + <em>δ</em><sub>x</sub> + <em>δ</em><sub>y</sub> + <em>δ</em><sub>m</sub>) + {O(<em>η</em><sup>2</sup>)}{≤ c ⋅ <em>η</em><sup>2</sup>}</p>
<p><span class="math inline">\(\frac{|x \cdot y - f(x \cdot y)|}{|x \cdot y|} = |\delta_x + \delta_y + \delta_m| + O(\eta^2) \leq 3 \eta + O(\eta^2)\)</span></p>
<h3 id="addition">Addition</h3>
<p><span class="math inline">\(f(x + y) = \[x(1 + \delta_x) + y(1 + \delta_y)\]\underbrace{(1 + \delta_a)}_{\text{error after rounding addition result}}
    &amp;= x(1 + \delta_x)(1 + \delta_a) + y(1 + \delta_y)(1 + \delta_a) = x(1 + \delta_x + \delta_a) + y(1 + \delta_y + \delta_a) + O(\eta^2) \\
    &amp;= (x + y) + x(\delta_x + \delta_a) + y(\delta_y + \delta_a) + O(\eta^2)\)</span></p>
<p><span class="math inline">\(|\frac{f(x + y) - (x + y)}{x + y}| \leq |\frac{x( \delta_x + \delta_a)}{x + y}| + |\frac{x( \delta_x + \delta_a)}{x + y}|\)</span></p>
<p>If <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> have same sign, <span class="math inline">\(|\frac{x}{x+y}| \leq 1\)</span> and <span class="math inline">\(|\frac{y}{x+y}| \leq 1\)</span>, then $ ≤|<em>δ</em><sub>x</sub> + <em>δ</em><sub>a</sub>| + |<em>δ</em><sub>y</sub> + <em>δ</em><sub>a</sub>| ≤ 4 <em>η</em>$</p>
<p>But if <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> have different sign, then <span class="math inline">\(|x - y|\)</span>, can be very small and potentialy causes the result to blow up.</p>
<p>We conclude that the result of any floating point arithmetic operation must be equal to the result using infinite precision then rounding to <span class="math inline">\(t\)</span> binary digits.</p>
<div class="examples">
<ol>
<li><p>Let <span class="math inline">\(b &gt;&gt; 4ac\)</span>, <span class="math inline">\(x_1 = \frac{-b - \sqrt{b^2 - 4ac}}{2a} \approx \frac{0}{2a}\)</span> <span class="math inline">\(x_2 = \frac{-b + \sqrt{b^2 - 4ac}}{2a}\)</span></p>
<p>To avoid cancellation, we can calculate the roots a different way:</p>
<p><span class="math inline">\(x_1 x_2 = \frac{c}{a} \Rightarrow x_1 = \frac{1}{x_2} \frac{c}{a}\)</span></p></li>
<li><p>Let <span class="math inline">\(x = 1.1103 \cdot 10^{-1}\)</span>, <span class="math inline">\(y = 9.963 \cdot 10^{-3}\)</span></p>
<p><span class="math inline">\(x - y = 1.337 \cdot 10^{-3}\)</span></p></li>
</ol>
</div>
<h3 id="subtraction">Subtraction</h3>
<p><span class="math inline">\(100.0 - 99.99 \Rightarrow 1.000 \cdot 10^2 - 0.9999 \cdot 10^2 = 0.001 \cdot 10^2\)</span></p>
<p><span class="math inline">\(fl(x-y) = .001 \cdot 10^2 = 0.1\)</span> <span class="math inline">\(\text{relative error} = \frac{0.1 - 0.01}{0.01} = 9\)</span></p>
<p><strong>with guard digit</strong></p>
<p><span class="math inline">\(100.0 - 99.99 \Rightarrow 1.0000 \cdot 10^2 - 0.9999 \cdot 10^2 = 0.01 \cdot 10^2\)</span></p>
<h1 id="condition-of-a-problem">Condition of a problem</h1>
<div class="definition">
<p><strong>condition number</strong> <span class="math inline">\(k_f(x) = |f&#39;(x)| \frac{|x|}{|f(x)|}\)</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>Let <span class="math inline">\(x \in \mathbb{R}, y = f(x), \hat{x} = fl(x), \hat{y} = {f(\hat{x})\)</span></p>
<p>relative error in input: <span class="math inline">\(\frac{|x - \hat{x}|}{|x|}\)</span></p>
<p>relative error in output: <span class="math inline">\(\frac{|y - \hat{y}|}{|y|} = \frac{|f(x) - f(\hat{x})|}{|f(x)|} = \frac{|f(x) - f(\hat{x})|}{|x - \hat{x}|} \cdot \frac{|x - \hat{x}|}{|x|} \cdot \frac{|x|}{|f(x)|}\)</span></p>

</div>
</div>

<div class="examples">
<ol>
<li><p><span class="math inline">\(f(x) = \tan{x}\)</span></p>
<p><span class="math inline">\(k_f(x) = \frac{|\sec^2 (x)| |x|}{|\tan x|} = \frac{|{x}|}{|\sin (x)||\cos (x)|}\)</span></p>
<p>As <span class="math inline">\(x \rightarrow \pi/2\)</span>, <span class="math inline">\(k_f(x) \rightarrow \infty\)</span>.</p></li>
<li><p>Let <span class="math inline">\(y_n = \int_0^1 \frac{x^n}{x + 10} dx\)</span></p>
<p><span class="math inline">\(y_n\)</span> should monotically decrease as <span class="math inline">\(n\)</span> increases. However, in computation we'll see that <span class="math inline">\(y_n\)</span> increases, then become negative.</p>
<p><span class="math inline">\(y_n = g(n) + (-10)^n y_0\)</span></p>
<p><span class="math inline">\(\frac{dy_n}{dy_0} = (-10)^n\)</span></p>
<p><span class="math inline">\(k_f(x) = \frac{10^n \cdot |x|}{|f(x)|} = \frac{10^n \cdot |y_0|}{|y_n|}\)</span></p>
<p><span class="math inline">\(k_f(x) &gt; 10^n\)</span></p></li>
</ol>
</div>
<h1 id="stability-of-an-algorithm">Stability of an Algorithm</h1>
<p>So far, we've defined two types of error. These errors require that we have the exact answer to the problem, <span class="math inline">\(y\)</span>.</p>
<div class="definition">
<p><strong>forward error</strong> <span class="math inline">\(\frac{|y - \hat{y}}{|y|}\)</span> <strong>absolute forward error</strong> <span class="math inline">\(|y - \hat{y}\)</span></p>
</div>
<p>For some problems, we don't have access to the exact answer, so we instead compute a different kind of error.</p>
<div class="definition">
<p><strong>backward error</strong> <span class="math inline">\(\frac{|x - \bar{x}|}{|x|}\)</span></p>
</div>
<div class="examples">
<ol>
<li><span class="math inline">\(fl(x_1 + x_2) = \[x_1(1 + \delta_1) + x_2(1 + \delta_2)\](1 + \delta_3) \\
   &amp;= x_1(1 + \delta_1)(1 + \delta_3) + x_2(1 + \delta_2)(1 + \delta_3) = \bar{x_1} + \bar{x_2}\)</span> <span class="math inline">\(\bar{x_1} = x_1(1 + \delta_1)(1 + \delta_3) = x_1 + x_1(\delta_1 + \delta_3) + O(\delta^2) \rightarrow \frac{|\bar{x_1} - x_1|}{x_1} \leq |\delta_1 + \delta_3| = 2 \eta\)</span></li>
<li><p>Let <span class="math inline">\(y = fl(x_1, x_2) = x_1^2 - x_2^2\)</span> using decimal arith. to 3 digits. Find the backwards error</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode octave"><code class="sourceCode octave"><a class="sourceLine" id="cb1-1" data-line-number="1">x1 = <span class="fl">12.5</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2">x2 = <span class="fl">0.333</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1-4" data-line-number="4">y1 = x1^<span class="fl">2</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5">y2 = x2^<span class="fl">2</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6">y1h = <span class="fl">156</span> <span class="co">## round y1 to 3 dig</span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7">y2h = <span class="fl">.111</span> <span class="co">## round y2 to 3 dig</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"></a>
<a class="sourceLine" id="cb1-9" data-line-number="9">y = y1 - y2</a>
<a class="sourceLine" id="cb1-10" data-line-number="10">yh = <span class="fl">156</span> <span class="co">## round y to 3 dig</span></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="co"># find d: x1^2 * (1 + d)^2 - x2^2 = yh</span></a>
<a class="sourceLine" id="cb1-13" data-line-number="13"><span class="fu">format</span> longe</a>
<a class="sourceLine" id="cb1-14" data-line-number="14">y1hat = <span class="fl">156</span></a>
<a class="sourceLine" id="cb1-15" data-line-number="15">y2hat = <span class="fl">1.11e-1</span></a>
<a class="sourceLine" id="cb1-16" data-line-number="16">yhat = y1hat - y2hat</a></code></pre></div></li>
</ol>
</div>
<div class="definition">
<p><strong>backwards stability</strong> An algorithm is backwards stable if the computed <span class="math inline">\(\hat{y}\)</span> satisfies</p>
<p><span class="math inline">\(\hat{y} = f(x + \delta)\)</span> where <span class="math inline">\(|\delta| \leq \varepsilon |x|\)</span></p>
<p>for any <span class="math inline">\(x\)</span> and a sufficiently small <span class="math inline">\(\varepsilon\)</span></p>
</div>
<div class="examples">

</div>
<p><span class="math inline">\(y_n = \int_0^1 \frac{x^n}{x + 10} dx\)</span> - the thing were trying to calculate</p>
<p><span class="math inline">\(y_n + 10y_{n-1} = \frac{1}{n}, n \geq 1\)</span> - the problem <span class="math inline">\(y_0 = \ln(11) - \ln(10)\)</span></p>
<p>when we calculate <span class="math inline">\(y_n\)</span> using floating point arithmetic, this is the algorithm</p>
<div class="examples">
<ol>
<li><div class="sourceCode" id="cb2"><pre class="sourceCode octave"><code class="sourceCode octave"><a class="sourceLine" id="cb2-1" data-line-number="1">y = <span class="fu">zeros</span>(<span class="fl">20</span>,<span class="fl">1</span>)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">y(<span class="fl">1</span>) = ln(<span class="fl">11</span>) - ln(<span class="fl">10</span>)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">for <span class="bn">i</span>=<span class="fl">2</span>:<span class="fl">20</span>, y(<span class="bn">i</span>) = <span class="fl">1</span>/<span class="bn">i</span> - <span class="fl">10</span>*y(<span class="bn">i</span>-<span class="fl">1</span>); end</a></code></pre></div></li>
</ol>
</div>
<h1 id="finding-roots">Finding Roots</h1>
<p><span class="math inline">\(y_{i+1} = -f(y_i)/f&#39;(y_i)\)</span></p>
<h2 id="intermediate-value-theorem">Intermediate Value Theorem</h2>
<p><strong>Intermediate value theorem</strong></p>
<div class="definition">
<p>Let <span class="math inline">\(f\)</span> be a continuous function in the domain <span class="math inline">\((a,\ b)\)</span>. For any <span class="math inline">\(y\)</span> s.t. <span class="math inline">\(f(a) \leq y \leq f(b)\)</span>, there exists <span class="math inline">\(x\)</span> such that <span class="math inline">\(a \leq x \leq b\)</span></p>
</div>
<h2 id="secant-method">Secant Method</h2>
<h3 id="convergence">Convergence</h3>
<h2 id="newtons-method">Newton's Method</h2>
<div class="definition">
<p><span class="math inline">\(x_{k+1} = x_k - \frac{f(x_k)}{f&#39;(x_k)}\)</span>, where <span class="math inline">\(x_1\)</span> is given. This find the point <span class="math inline">\(x^*\)</span> such that <span class="math inline">\(f(x^*) = 0\)</span></p>
</div>
<h3 id="convergence-1">Convergence</h3>
<div class="definition">
<ul>
<li>Newton's method converges quadratically.</li>
</ul>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>$\begin{aligned} g'(x) &amp;= 1 - <br />
&amp; = 1 - <br />
&amp; =  \end{aligned}$</p>
<p>Let <span class="math inline">\(x = x^*\)</span></p>
<p><span class="math inline">\(g&#39;(x) = \frac{f(x^*)f&#39;&#39;(x^*)}{f&#39;(x^*)^2} = 0\)</span> for <span class="math inline">\(f&#39;(x^*) \neq 0\)</span></p>
<p>If we write <span class="math inline">\(g(x_k)\)</span> as taylor series:</p>
<p><span class="math inline">\(g(x_k) = g(x^*) + (x_k - x^*) g&#39;(x^*) + (x_k - x^*)^2 g&#39;&#39;(\psi) \\
&amp; = x^* + \frac{(x_k - ^*)^2}{2} g&#39;&#39;(\zeta) \end{aligned}\)</span></p>
<p><span class="math inline">\(\text{e_{k+1}} &amp; = (x_{k+1} - x^*) = \frac{(x_k - x^*)^2}{2} g&#39;&#39;(\psi) \\
&amp; = \frac{e_k^2}{2} \cdot \g&#39;&#39;(\psi)| \end{aligned}\)</span></p>
<p>Suppose <span class="math inline">\(|g&#39;&#39;(x)| \leq M\)</span> for <span class="math inline">\(x \in [a,b]\)</span>, <span class="math inline">\(e_{k+1} \leq \frac{M}{2} e_k^2\)</span></p>
<p>So Newton's method converges quadratically.</p>

</div>
</div>

<div class="definition">
<ul>
<li>Newton's method exhibits local convergence</li>
</ul>
</div>
<h2 id="bisection-method">Bisection Method</h2>
<h3 id="convergence-2">Convergence</h3>
<div class="definition">
<ul>
<li>the Bisection method converges globally</li>
</ul>
</div>
<h2 id="fixed-point-iteration">Fixed point iteration</h2>
<p>This can be interpreted <span class="math inline">\(x_{k+1} = g(x_k)\)</span> When the solution <span class="math inline">\(x^*\)</span> is found, <span class="math inline">\(x^* = g(x^*)\)</span></p>
<p>There are many functions <span class="math inline">\(g\)</span> such that <span class="math inline">\(x^* = g(x^*)\)</span>, like <span class="math inline">\(g(x) = x + \alpha f(x)\)</span></p>
<div class="theorem">
<p>Let <span class="math inline">\(g\)</span> be a function such that.</p>
<ol>
<li>G is continuous on <span class="math inline">\([a,b]\)</span></li>
<li><span class="math inline">\(g(a) \geq a\)</span>, <span class="math inline">\(g(b) \leq b\)</span></li>
<li>differentiable on <span class="math inline">\([a,b]\)</span></li>
<li><span class="math inline">\(|g&#39;(x)| &lt; 1\)</span> on <span class="math inline">\([a,b]\)</span></li>
</ol>
<p>Then</p>
<ul>
<li>there exists a point <span class="math inline">\(x^* \in [a,b]\)</span> such that <span class="math inline">\(g(x^*) = x^*\)</span></li>
<li>the stationary point <span class="math inline">\(x^*\)</span> is unique</li>
<li><span class="math inline">\(x_{k+1} = g(x_k)\)</span> will converge to <span class="math inline">\(x^*\)</span> given <span class="math inline">\(x_1 \in [a,b]\)</span></li>
</ul>
</div>
<p>Assume <span class="math inline">\(g(a) - a &gt; 0\)</span> and <span class="math inline">\(g(b) - b &lt; 0\)</span></p>
<p>From IVT, there exists some <span class="math inline">\(x^* \in [a,b]\)</span> such that <span class="math inline">\(g(x^*) - x^* = 0\)</span></p>
<h3 id="uniqueness">Uniqueness</h3>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>Assume for contradiction that <span class="math inline">\(x^* = y^*\)</span></p>
<p><span class="math inline">\(|x^* - y^*| = |g(x^*) - g(y^*)|\)</span></p>
<p>Let <span class="math inline">\((y^*) = g(x^*) + (y^* - x^*) g&#39;(\zeta)\)</span>, where <span class="math inline">\(\zeta \in [x^*, y^*]\)</span></p>
<p><span class="math inline">\(|x^* - y^*| = |g&#39;(\zeta) \cdot (y^* - x^*)| = |g&#39;(\zeta)|\cdot |x^* - y^*|\)</span> ≤ |x<sup>*</sup> - y<sup>*</sup>|$</p>
<p>So <span class="math inline">\(x^* = y^*\)</span></p>

</div>
</div>

<h3 id="convergence-3">Convergence</h3>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p><span class="math inline">\(x_{k+1} = g(x_k) = g(x^*) + (x_k - x^*) \cdot g&#39;(\zeta)\)</span> for <span class="math inline">\(\zeta \in [x_k, x^*]\)</span></p>
<p><span class="math inline">\(= x^* + (x_k - x^*) \cdot g&#39;(\zeta)\)</span></p>
<p><span class="math inline">\(x_{x+1} - x^* = (x_k - x^*) \cdot g&#39;(\psi)\)</span></p>
<p>Where <span class="math inline">\(x_{x+1} - x^*\)</span> is the error <span class="math inline">\(e_{k+1}\)</span></p>
<p><span class="math inline">\(e_{k+1} = e_k \cdot |g&#39;(\zeta)| \leq l \cdot e_k \leq l \cdot (l e_{k-1} = l^2 e_{k-1} \leq l^k e_1\)</span></p>
<p>So <span class="math inline">\(\lim_{k \rightarrow \infty} l^k = 0\)</span>, and <span class="math inline">\(e_{k+1} = |x_{k+1} - x^*| = 0\)</span></p>

</div>
</div>

<h2 id="implementation">Implementation</h2>
<p>Root finding scripts combine multiple methods to achieve speed and reliability in finding roots of <span class="math inline">\(f\)</span></p>
<ol>
<li>check <span class="math inline">\(f\)</span> at an initial guess <span class="math inline">\(x_1\)</span> and finds two points <span class="math inline">\(a,b\)</span> around <span class="math inline">\(x_1\)</span> such that the signs of <span class="math inline">\(f(a)\)</span> and <span class="math inline">\(f(b)\)</span> are different</li>
<li>iterate newtons method a few times until error stops decreasing significantly
<ul>
<li>(for example, iterate until <span class="math inline">\(\text{curr. err} \leq \frac{\text{prev. err.}}{2} = |x_{k+1} - x_k | \leq \frac{|x_k - x_{k-1}|}{2}\)</span></li>
</ul></li>
</ol>
<h2 id="condition-number">Condition Number</h2>
<p>We can't use the relative condition number, <span class="math inline">\(k_r(x) = \frac{|x| \cdot |f&#39;(x)|}{|f(x)|}\)</span>, since <span class="math inline">\(k_r \rightarrow \infty\)</span> as <span class="math inline">\(f(x) \rightarrow 0\)</span>.</p>
<p>Instead we use the absolute condition number to quantify the problem.</p>
<div class="definition">
<p><strong>absolute condition number</strong></p>
<p><span class="math inline">\(k_a(x) = |f&#39;(x)|\)</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p><strong>absolute condition number</strong> <span class="math display">\[|y - \hat{y}| = k_a(x) |x - \hat{x}|\]</span> <span class="math display">\[\hat{y} = f(\hat{x}) = f(x) + (x - \hat{x}) f&#39;(\psi)\]</span> where <span class="math inline">\(\psi \in [x, \hat{x}]\)</span> <span class="math display">\[y - \hat{x} = f(x) - f(x) - (x - \hat{x}) f&#39;(\psi)\]</span> <span class="math display">\[|y - \hat{y}| = |(x - \hat{x}) f&#39;(\psi)| \approx |f&#39;(x)| \cdot |x - \hat{x}|\]</span> <span class="math inline">\(k_a(x) = |f&#39;(x)|\)</span></p>

</div>
</div>

<p><span class="math display">\[\log_{10} | \thing{\frac{y - \hat{y}}{y}}{10^{-p}} | = \log_{10} k_r + \log_{10} | \thing{\frac{x - \hat{x}}{x}}{10^{-16}} |\]</span></p>
<p><span class="math inline">\(p = 16 - \log_{10} k_r\)</span></p>
<p>When finding roots, we find <span class="math inline">\(x\)</span> given <span class="math inline">\(y\)</span>, so <span class="math inline">\(x = f^{-1}(y) \rightarrow k_r = \frac{|y| \cdot |f^{-1}&#39;(y)|}{ |f^{-1}(y)| }\)</span>.</p>
<p><span class="math inline">\(f^{-1}&#39;(y) = \frac{d}{dy} f^{-1} (y) = \frac{dx}{dy} = \frac{1}{dy/dx} = \frac{1}{f&#39;(x)}\)</span></p>
<p><span class="math inline">\(k_{r,f^{-1}} = \frac{|f(x)|}{|x| \cdot |f&#39;(x)|}\)</span></p>
<p><span class="math inline">\(\hat{y} - y = (\hat{x} - x) f&#39;(\psi)\)</span> <span class="math inline">\(|\hat{y} - y| = |(\hat{x} - x)| |f&#39;(\psi)|\)</span> where <span class="math inline">\(\psi \in [x,\hat{x}]\)</span></p>
<p>Approximate <span class="math inline">\(f&#39;(\psi)\)</span> with <span class="math inline">\(f&#39;(x)\)</span></p>
<p><span class="math inline">\(|\hat{y} - y| \approx |f&#39;(x)| \cdot |\hat{x} - x|\)</span></p>
<p><span class="math inline">\(|\hat{x} - x| = \frac{1}{|f&#39;(x)|} |\hat{y} - y|\)</span></p>
<p><span class="math inline">\(k_a = \frac{1}{|f&#39;(x)|}\)</span></p>
<div class="examples">
<ol>
<li><p>Find the roots of <span class="math inline">\(\sin (x)\)</span> <span class="math inline">\(y = 0 = x - \sin (x) = f(x)\)</span> <span class="math inline">\(f&#39;(x) = x - \sin (x)\)</span></p>
<p><span class="math inline">\(k_a = \frac{1}{|f&#39;(x)|} = \frac{1}{|1 - \cos x|}\)</span></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode octave"><code class="sourceCode octave"><a class="sourceLine" id="cb3-1" data-line-number="1">f = @(x) x - <span class="fu">sin</span>(x)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="fu">fzero</span>(f, <span class="fl">0.1</span>)  <span class="co"># -2.0735e-08 : error in precision in 10^-16, but error in root is much larger</span></a>
<a class="sourceLine" id="cb3-3" data-line-number="3"></a>
<a class="sourceLine" id="cb3-4" data-line-number="4">g = @(x) x - <span class="fu">sin</span>(x) - <span class="fl">1e-14</span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="fu">fzero</span>(g, <span class="fl">0.1</span>)  <span class="co"># 3.9149e-05 : this error is smaller because we are instead finding a solution at y=1e-14, so the condition number doesn&#39;t blow up</span></a></code></pre></div></li>
<li><p>Find the roots of <span class="math inline">\((x - 1)(x - 2) \dots (x - 20)\)</span> (Wilkinson's polynomial)</p></li>
</ol>
</div>
<h2 id="matrices">Matrices</h2>
<p><span class="math display">\[Ax = b\]</span></p>
<p><span class="math inline">\(x_1 + x_2 = 3\)</span> <span class="math inline">\(x_1 - x_2 = 1\)</span></p>
<p><span class="math display">\[\begin{matrix} 1 &amp; 1 \\ 1 - 1 \end{matrix} \cdot \begin{matrix} x_1 \\ x_2 \end{matrix} = \begin{matrix} 3 \\ 1\]</span></p>
<p>Relative condition: A(x + <em>δ</em> x) = b + <em>δ</em> b</p>
<p><span class="math display">\[\frac{|| \delta x ||}{|| x ||} = k_r \cdot \frac{|| \delta b ||}{|| b ||}\]</span></p>
<p><span class="math inline">\(k_r = || A || \cdot || A^{-1} ||\)</span></p>
<p><span class="math display">\[|| A ||_1 = max_{1 \leq j \leq n} \sum_{i=1}^n |a_{ij}|\]</span> - max column sum norm <span class="math display">\[|| A ||_\infty = max_{1 \leq i \leq n} \sum_{j=1}^n |a_{ij}|\]</span> - max row sum norm</p>
<div class="examples">
<ol>
<li><pre><code>H = hilb(5)
b = sum(H, 2)

H\b
</code></pre></li>
<li><pre><code>P = pascal(5)
b = sum(P, 2)
</code></pre></li>
</ol>
</div>
<h1 id="finding-minimums">Finding Minimums</h1>
<pre><code>f = @(x) x.^2 - x - 2; # parabola with minimum at x = .5

x = fminbnd(f, -2, -3)
</code></pre>
<p>Assume we are trying to minimize a function <span class="math inline">\(\phi (x)\)</span>, where <span class="math inline">\(x^*\)</span> is the location of the minimum (minimizer).</p>
<p>Assume <span class="math inline">\(\phi (x)\)</span> is twice differentiable.</p>
<p>Writing <span class="math inline">\(\phi\)</span> as a taylor series: <span class="math display">\[\phi (x) = \phi (x^*) + (x - x^*) \phi &#39;(x^*) + \frac{(x - x^*)^2}{2} \phi &#39;&#39;(x^*) + O((x - x^*)^3)\]</span></p>
<p>Since <span class="math inline">\(x^*\)</span> is a minimizer, <span class="math inline">\(\phi &#39;(x^*) = 0\)</span>, so <span class="math display">\[\phi (x) = \phi (x^*) + \frac{(x - x^*)^2}{2} \phi &#39;&#39;(x^*) + O((x - x^*)^3)\]</span></p>
<p>If <span class="math inline">\(\phi &#39;&#39;(x^*) &gt; 0\)</span>, then <span class="math inline">\(x^*\)</span> is a minimizer, and if <span class="math inline">\(\phi &#39;&#39;(x^*) &lt; 0\)</span>, then <span class="math inline">\(x^*\)</span> is a maximizer. If <span class="math inline">\(\phi &#39;&#39;(x^*) = 0\)</span>, there is not enough information to know.</p>
<h2 id="implementation-1">Implementation</h2>
<p>A common minimum finder employs two methods:</p>
<ol>
<li>Golden section search</li>
<li>Parabolic interpolation</li>
</ol>
<div class="sourceCode" id="cb7"><pre class="sourceCode octave"><code class="sourceCode octave"><a class="sourceLine" id="cb7-1" data-line-number="1">f = @(x) x.^<span class="fl">2</span> + <span class="fl">4</span> * <span class="fu">cos</span>(x);</a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="fu">fplot</span>(f, [<span class="fl">0</span> <span class="fl">3</span>]);</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">options = <span class="fu">optimset</span>(<span class="st">&#39;Display&#39;</span>, <span class="st">&#39;iter&#39;</span>);</a>
<a class="sourceLine" id="cb7-4" data-line-number="4">[xmin, <span class="fu">fmin</span>] = <span class="fu">fminbnd</span>(f, <span class="fl">0</span>,<span class="fl">3</span>, options);</a></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode octave"><code class="sourceCode octave"><a class="sourceLine" id="cb8-1" data-line-number="1">octave:<span class="fl">4</span>&gt;     [xmin, <span class="fu">fmin</span>] = <span class="fu">fminbnd</span>(f, <span class="fl">0</span>,<span class="fl">3</span>, options);</a>
<a class="sourceLine" id="cb8-2" data-line-number="2"></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">Func-<span class="fu">count</span>     x          f(x)    Procedure</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">    <span class="fl">1</span>        <span class="fl">1.85410</span>    <span class="fl">2.319570</span> initial</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">    <span class="fl">2</span>        <span class="fl">2.29180</span>    <span class="fl">2.611785</span> golden</a>
<a class="sourceLine" id="cb8-6" data-line-number="6">    <span class="fl">3</span>        <span class="fl">1.83004</span>    <span class="fl">2.323648</span> parabolic</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">    <span class="fl">4</span>        <span class="fl">1.88882</span>    <span class="fl">2.316881</span> parabolic</a>
<a class="sourceLine" id="cb8-8" data-line-number="8">    <span class="fl">5</span>        <span class="fl">1.89619</span>    <span class="fl">2.316809</span> parabolic</a>
<a class="sourceLine" id="cb8-9" data-line-number="9">    <span class="fl">6</span>        <span class="fl">1.89554</span>    <span class="fl">2.316808</span> parabolic</a>
<a class="sourceLine" id="cb8-10" data-line-number="10">    <span class="fl">7</span>        <span class="fl">1.89549</span>    <span class="fl">2.316808</span> parabolic</a>
<a class="sourceLine" id="cb8-11" data-line-number="11">    <span class="fl">8</span>        <span class="fl">1.89549</span>    <span class="fl">2.316808</span> parabolic</a>
<a class="sourceLine" id="cb8-12" data-line-number="12">    <span class="fl">9</span>        <span class="fl">1.89549</span>    <span class="fl">2.316808</span> parabolic</a>
<a class="sourceLine" id="cb8-13" data-line-number="13">   <span class="fl">10</span>        <span class="fl">1.89549</span>    <span class="fl">2.316808</span> parabolic</a>
<a class="sourceLine" id="cb8-14" data-line-number="14">   <span class="fl">11</span>        <span class="fl">1.89549</span>    <span class="fl">2.316808</span> golden</a>
<a class="sourceLine" id="cb8-15" data-line-number="15"></a>
<a class="sourceLine" id="cb8-16" data-line-number="16">Optimization terminated:</a>
<a class="sourceLine" id="cb8-17" data-line-number="17">the current x satisfies the termination criteria using OPTIONS.TolX of <span class="fl">1.000000e-08</span></a></code></pre></div>
<h3 id="golden-section-search">Golden Section Search</h3>
<p>Assume <span class="math inline">\(f\)</span> is a unimodal function (only one minimum).</p>
<p><span class="math inline">\(\tau = \frac{\sqrt{5} - 1}{2} \approx 0.618\)</span></p>
<ol>
<li><p>Begin with two points, <span class="math inline">\(x_1 = a + (1 - \tau)(b - a)\)</span>, <span class="math inline">\(x_2 = a + \tau (b - a)\)</span></p>
<p>case 1: if <span class="math inline">\(f(x_1) &lt; f(x_2)\)</span>, then there must be a minimum in the range <span class="math inline">\([a, x_2]\)</span></p>
<p>case 2: if <span class="math inline">\(f(x_1) &gt; f(x_2)\)</span>, then there must be a minimum in the range <span class="math inline">\([x_1, b]\)</span></p></li>
<li><p>Find two new points <span class="math inline">\(x_1, x_2\)</span> in the new range, noticing that the unused existing point is already in the right place, ie:</p>
<p>case 1: <span class="math inline">\(x_2&#39; = x_1\)</span></p>
<p>case 2: <span class="math inline">\(x_1&#39; = x_2\)</span></p></li>
</ol>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>case 1: <span class="math inline">\(\frac{x_1 - a}{x_2 - a} = \frac{(1 - \tau)(b - a)}{\tau (b - a)} = \tau\)</span>, so <span class="math inline">\(x_1\)</span> is already located in the right spot. case 2: $ = $, so <span class="math inline">\(x_1\)</span> is already located in the right spot.</p>

</div>
</div>

<p>The new length of the interval after each iteration is <span class="math inline">\(\tau\)</span> of its previous length.</p>
<h3 id="parabolic-interpolation">Parabolic Interpolation</h3>
<ol>
<li><p>Start with 3 points, <span class="math inline">\(u, v, w\)</span>, such that v is the minimizer: $f(v) &lt; f(u), f(w)$$</p></li>
<li><p>Draw a parabola <span class="math inline">\(p(x)\)</span> that goes through the points <span class="math inline">\((u,\ f(u))\ ,(v,\ f(v))\ ,(w,\ f(w)))\)</span></p></li>
<li><p>Find the minimum of the parabola, <span class="math inline">\(m\)</span></p></li>
<li><p>case 1: if <span class="math inline">\(m &lt; v\)</span>, then <span class="math inline">\(u&#39;=u,\ v&#39;=m\ ,w&#39; = v\)</span></p>
<p>case 2: if <span class="math inline">\(m &gt; v\)</span>, then $u</p></li>
</ol>
<h3 id="solving-for-minimum-of-parabola">Solving for minimum of parabola</h3>
<p><span class="math inline">\(L(x) = \frac{f(u)(x - v)(x - w)}{(u-v)(u-w)} + \frac{f(v)(x - u)(x - w)}{v - i)(v - w)} + \frac{f(w)(x - u)(x - v)}{w - u)(w - v)}\)</span></p>
<p><span class="math inline">\(L&#39;(x) = 0\)</span></p>
<p><span class="math inline">\(p = (v - u)^2(f(w) - f(v) - (v - w)^2(f(u) - f(v))\)</span></p>
<h1 id="interpolation">Interpolation</h1>
<p>Interpolation allows us to:</p>
<ul>
<li>data fitting - if we only have a limited number of sample points, we can find a function that fits the data</li>
<li>approximate functions that are difficult to compute - we can compute a function at a handful of points then interpolate to fill in the gaps</li>
</ul>
<h2 id="power-basis">Power basis</h2>
<p>Given a set of coordinates <span class="math inline">\((x_i, y_i), \cdots, (x_n, y_n)\)</span>, find a function that interpolates the values. We limit the the function to a polynomial of <span class="math inline">\(n\)</span> degrees to keep the function simple.</p>
<p>Let <span class="math inline">\(P_n(x) = a_1 x^n + \cdots a_n x + a_{n+1}\)</span> be an nth degree polynomial.</p>
<p><span class="math display">\[\underbrace{\left[ \begin{matrix} x_1^n &amp; \cdots &amp; x_1 &amp; 1 \\ x_2^n &amp; \cdots &amp; x_2 &amp; 1 \\ \vdots  &amp; \vdots &amp; \vdots &amp; \vdots \\ x_{n+1}^n &amp; \cdots &amp; x_{n+1} &amp; 1 \end{matrix} \right]}_{V} \left[ \begin{matrix} a_1 \\ a_2 \\ a_3 \\ a_3 \end{matrix} \right] = \left[ \begin{matrix} y_1 \\ y_2 \\ \vdots \\ y_{n+1}\end{matrix} \right]\]</span></p>
<p>If <span class="math inline">\(x_i \neq x_ x_j\)</span>, then <span class="math inline">\(Va = y\)</span> has a unique solution. <span class="math inline">\(a\)</span> contains the coefficients of the interpolation polynomial.</p>
<p>The basis here is <span class="math inline">\({x^n, x^{n-1}, \cdots, x, 1}\)</span> and is known as a power basis.</p>
<p>#+begin<sub>examples</sub></p>
<ol>
<li><p>(1,16), (3,21), (5,15), (15,12). Fit to a 3rd degree polynomial: <span class="math inline">\(P_3(x) = a_1 x^3 + a_2 x^2 + a_3 x + a_4\)</span></p>
<p><span class="math display">\[\left[ \begin{matrix} 1 &amp; 1 &amp; 1 &amp; 1 \\ 27 &amp; 9 &amp; 3 &amp; 1 \\ 125 &amp; 25 &amp; 5 &amp; 1 \\ 216 &amp; 36 &amp; 6 &amp; 1 \end{matrix} \right] \left[ \begin{matrix} a_1 \\ a_2 \\ a_3 \\ a_3 \end{matrix} \right] = \left[ \begin{matrix} 16 \\ 21 \\ 15 \\ 12\end{matrix} \right]\]</span></p>
<span class="math inline">\(V\)</span> is the Vander Monde matrix, and if <span class="math inline">\(x_i \neq x_j\)</span>, then <span class="math inline">\(V\)</span> is non-singular</li>
</ol>
<p>#+end<sub>exapmles</sub></p>
<p>However Vander Monde matrices are known for being ill-conditioned, so this is not a good method for computing interpolating polynomials.</p>
<h2 id="general-matrix-form">General matrix form</h2>
<p>Let the basis functions be <span class="math inline">\(\phi_1 (x), \phi_2 (x), \cdots, \phi_{n+1} (x)\)</span></p>
<p><span class="math inline">\(y = c_1 \phi_1 (x) \cdot + \phi_{n+1} (x)\)</span></p>
<p><span class="math display">\[\left[ \begin{matrix} \phi_1 (x_1) &amp; \cdots &amp; \phi_n (x_1) &amp; \phi_{n+1} (x_1) \\ \phi_1 (x_2) &amp; \cdots &amp; \phi_n (x_2) &amp; \phi_{n+1} (x_2) \\ \vdots  &amp; \vdots &amp; \vdots &amp; \vdots \\ \phi_1 (x_{n+1}) &amp; \cdots &amp; \phi_n (x_{n+1) &amp; \phi_{n+1} (x_{n+1}) \end{matrix} \right] \left[ \begin{matrix} a_1 \\ a_2 \\ a_3 \\ a_3 \end{matrix} \right] = \left[ \begin{matrix} y_1 \\ y_2 \\ \vdots \\ y_{n+1}\end{matrix} \right]\]</span></p>
<h2 id="lagrange-basis">Lagrange basis</h2>
<p><span class="math display">\[L_i(x) = \frac{(x - x_1)(x - x_2) \cdot (x - x_{i-1}) (x - x_{i+1}) \cdot (x - x_{n+1})}{(x_i - x_1) (x_i - x_2) \cdots (x_i - x_{i-1}) (x_i - x_{i+1}) \cdots (x_1 - x_{n+1})}\]</span></p>
<p><span class="math inline">\(L_i\)</span> has the property that <span class="math display">\[L_i(x_j) = \begin{cases} 1 &amp; i = j \\ 0 &amp; i \neq j \end{cases}\]</span></p>
<p><span class="math inline">\(L(x) = y_1 L_1 (x) + y_2 L_2 (x) + \cdots + y_{n+1} L_{n+1} (x)\)</span></p>
<p>Each <span class="math inline">\(L_i (x)\)</span> is an nth degree polynomial.</p>
<p><span class="math display">\[L(x) = \sum_1^{n+1} y_i L_i (x)\]</span></p>
<p>Where <span class="math display">\[L_i(x) = \frac{\prod_1^{n+1} (x - x_i)}{\prod_1^{n+1} (x - x_j)}\]</span></p>
<p>Let <span class="math inline">\(\psi(x) = \prod_{j = 1}^{n + 1} \frac{f(x_i)}{ x - x_j} w_i\)</span></p>
<p><span class="math display">\[w_i = \frac{1}{\prod_{j = 1,\ j \neq i}^{n+1} (x_i - x_j)}\]</span></p>
<p>$Li(x) = </p>
<p><span class="math display">\[L = \sum_i=1^{n+1} y_i \frac{\phi (x)}{x - x} \cdot w_ifdA

   \]</span>L9x) <em>ϕ</em>(x) \</p>
<p><span class="math inline">\(L(x) = \frac{\sum_{i=1}^{n+1} \frac{z_i x - x_i}}\)</span></p>
<h1 id="newton-form-interpolating-polynomial">Newton Form Interpolating Polynomial</h1>
<div class="definition">
<p><span class="math inline">\(P_n(x)  = f[x_1] + \underbrace{f[x_1, x_2]}_{\text{divided difference}}(x - x_1) + \dots + f[x_1, x_2, \dots, x_n](x - x_1) \dots (x - x_n)\)</span></p>
<p><span class="math display">\[P_n(x) = \sum_{i=1}^{n+1} \left[ f[x_1, \cdots, x_i] \prod_{j=1}^{i=1} (x - x_j) \right]\]</span></p>
</div>
<p>The divided difference approaches the derivative if all <span class="math inline">\(x_i\)</span> begin to approach the same point: <span class="math display">\[\lim_{(x_0, \cdots, x_n) \rightarrow (x, \cdots, x)} f[x_0, \cdots, x_n] = f^{(n)}(x)\]</span></p>
<p>So the Newton form polynomial is equivalent to a Taylor polynomial if all <span class="math inline">\(x_i\)</span> begin to approach the same point: <span class="math display">\[\lim_{(x_0, \cdots, x_n) \rightarrow (x, \cdots, x)} f[x_1] + f[x_1, x_2](x - x_1) + \dots + f[x_1, x_2, \dots, x_n](x - x_1) \dots (x - x_n) = f(x) + (\varepsilon - x) f&#39;(x) + (\varepsilon - x)^2 \frac{f(x)}{2!} + \cdots + (\varepsilon - x)^n \frac{f(x)^(n)}{(n!)}\]</span></p>
<h2 id="divided-difference">Divided difference</h2>
<div class="definition">
<p><span class="math display">\[f[x_0, \cdots, x_n] = \frac{f[x_1, \cdots, x_n] - f[x_0, \cdots, x_{n-1}]}{x_n - x_0}\]</span></p>
<p>where</p>
<p><span class="math display">\[f[x_0, x_1] = \frac{f[x_1] - f[x_0]}{x_1 - x_0}\]</span></p>
<p><span class="math display">\[f[x_1, x_2] = \frac{f[x_2] - f[x_1]}{x_2 - x_1}\]</span></p>
<p><span class="math display">\[f[x_0, x_1, x_2] = \frac{f[x_1, x_2] - f[x_0, x_1]}{x_2 - x_0}\]</span></p>
<p><span class="math display">\[\cdots\]</span></p>
</div>
<h2 id="interpolation-with-derivatives">Interpolation with Derivatives</h2>
<p><span class="math display">\[f[x_1, x_2] = \frac{f[x_2] - f[x_1]}{x_2 - x_1}\]</span></p>
<p><span class="math display">\[\lim_{x_2 \rightarrow x_1} f&#39;(x_2)\]</span></p>
<p>so define <span class="math inline">\(f[x_1, x_1] = f&#39;(x_1)\)</span>,<span class="math inline">\(\underbrace{f[x_1, x_1,\dots , x_1]}_{\text{k+1 times}} = \frac{f^{(k)}}(x_1){k!}\)</span></p>
<div class="definition">
<p>Given the points <span class="math inline">\(t_1, t_2, \cdots, t_q\)</span> and multiplicities <span class="math inline">\(m_1, m_2, \cdots, m_q\)</span></p>
<p>we can find an inteprolating polynomial such that <span class="math inline">\(p^{(k)}(x_i) = f^{(k)}(x_i)\)</span>, for <span class="math inline">\(k \in [0,m_i]\)</span></p>
<p>We have <span class="math inline">\(\sum_{i=1}^q (m_i + 1) = \sum_{i= 1}^q (m_i + q)\)</span> constraints.</p>
</div>
<div class="examples">
<ol>
<li><p>Assume we want to find a polynomial that interpolates the points, <span class="math inline">\(f(0) = 1\)</span>, <span class="math inline">\(f&#39;(x) = -1\)</span>, <span class="math inline">\(f(1) = 1\)</span></p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(x_i\)</span></th>
<th><span class="math inline">\(f[x]\)</span></th>
<th><span class="math inline">\(f[x,x]\)</span></th>
<th><span class="math inline">\(f[x,x,x]\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(x_0 = 0\)</span></td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_0 = 0\)</span></td>
<td>1</td>
<td><span class="math inline">\(f[x_0, x_0] = f&#39;(x_0) = -1\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(x_1 = 1\)</span></td>
<td>1</td>
<td><span class="math inline">\(f[x_0, x_1] = \frac{f[x_1] - f[x_0]}{x_1 - x_0} = 0\)</span></td>
<td><span class="math inline">\(f[x_0, x_0, x_1 = \frac{f[x_0, x_1] - f[x_0, x_0]}{x_1 - x_0} = 0\)</span></td>
</tr>
</tbody>
</table>
<p>Interpolating polynomial: <span class="math inline">\(1 - 1 \cdot(x-0) + 1 \cdot(x - 0)^2\)</span> = x<sup>2</sup> - x + 1$</p></li>
<li><p>Find a polynomial such that <span class="math inline">\(f(0) = -1, f&#39;(0) = 1, f(1) = 0, f&#39;(1) = 2\)</span></p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(x_i\)</span></th>
<th><span class="math inline">\(f[x]\)</span></th>
<th><span class="math inline">\(f[x, x]\)</span></th>
<th><span class="math inline">\(f[x, x, x]\)</span></th>
<th><span class="math inline">\(f[x, x, x, x]\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(t_1 = 0\)</span></td>
<td>-1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(t_1 = 0\)</span></td>
<td>-1</td>
<td>f[t<sub>1</sub>, t<sub>2</sub>] = f'(t<sub>1</sub>) = -1$</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(t_2 = 1\)</span></td>
<td>0</td>
<td><span class="math inline">\(f[t_1, t_2] = \frac{f[1] - f[0]}{1 - 0} = 1\)</span></td>
<td><span class="math inline">\(f[t_1, t_1, t_2] = \frac{1 - 1}{1 - 0} = 0\)</span></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td><span class="math inline">\(f[t_2, t_2] = f&#39;(t_2) = 2\)</span></td>
<td><span class="math inline">\(f[t_1, t_2, t_2] = \frac{f[t_2, t_2] - f[t_1, t_2]}{t_2 - t_1} = 1\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td><span class="math inline">\(f[t_1, t_1, t_2, t_2] = \frac{f[t_1, t_2, t_2] - f[t_1, t_1, t_2]}{t_2 - t_1} = 1\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(P_3(x) = - 1+ 1 \cdot(x - 0) + (x - 0)^2 + 1 \cdot (x - 0)^2 (x - 1) = x^3 - x^2 + x - 1\)</span> <span class="math inline">\(P_3&#39;(x) = 3x^2 - 2x + 1\)</span></p>
<p>We can verify this polynomial at various values</p>
<table>
<thead>
<tr class="header">
<th>x</th>
<th><span class="math inline">\(P_3(x)\)</span></th>
<th><span class="math inline">\(P_3&#39;(x)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>-1</td>
<td>1</td>
</tr>
<tr class="even">
<td>1</td>
<td>0</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>So this meets the original constraints.</p></li>
</ol>
</div>
<h2 id="error-1">Error</h2>
<p><span class="math display">\[e_n(x) = |f(x) - P_n(x)| = \frac{f^{(n+1)}(\zeta) }{(n+1)!} \phi(x)\]</span>, where <span class="math inline">\(\phi(x) = (x - x_1) \cdots (x - x_{n+1})\)</span> and <span class="math inline">\(\frac{f^{(n+1)}(\zeta)}{(n+1)!} = f[x_1, x_2, \cdots, x_{n+1}, x]\)</span></p>
<p>for <span class="math inline">\(n=1\)</span>, <span class="math inline">\(P_1(x) = f[x_1] + f[x_1, x_2](x - x_1)\)</span>.</p>
<div class="examples">
<ol>
<li><p><span class="math display">\[e_1(x) = |f(x) - P_1(x)| = |\frac{f&#39;&#39;(\zeta)}{2}| \cdot |(x - x_1)(x - x_2)| \leq \frac{1}{2} \text{max} |f&#39;&#39;(\zeta)| \cdot \text{max}_{x \in[x_1, x_2]} | (x - x_1)(x - x_2)|\]</span></p>
<p>where the max of <span class="math inline">\((x - x_1)(x - x_2)\)</span> is <span class="math inline">\(x = \frac{x_1 + x_2}{2}\)</span> which evaluates to <span class="math inline">\(\frac{(x_2 - x_1)^2}{4}\)</span></p>
<p>so <span class="math inline">\(e_1(x) \leq \frac{1}{2} \cdot \frac{(x_2 - x_1)^2}{4} \cdot \text{max}_{\zeta \in [x_2, x_2]} f&#39;&#39;(\zeta)\)</span></p></li>
</ol>
</div>
<p>Error in the polynomial is driven by two terms:</p>
<ul>
<li>the derivative of f</li>
<li>placement of interpolated points - equally spaced points usually drive this term high and lead to a large error. See <strong>chebyshev polynomial</strong> for information about ideal point placement.</li>
</ul>
<h2 id="horners-method">Horner's Method</h2>
<p><span class="math inline">\(P = c_{n+1} (x - x_n)\)</span></p>
<p><span class="math inline">\(P = \left[ P + c_n \right] (x - x_{n-1})\)</span></p>
<p>$P = [<em>P</em>+<em>c</em><sub><em>n</em> − 1</sub>] (x - x<sub>n-2</sub>)</p>
<p>jth iteration</p>
<p><span class="math inline">\(P = \left[ P + c_j \right] (x - x_{j-1})\)</span></p>
<p><strong>Pseudo code</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode octave"><code class="sourceCode octave"></code></pre></div>
<h1 id="chebyshev-interpolating-points.">Chebyshev Interpolating points.</h1>
<p><a href="./chebyshev.png"><img src="./chebyshev.png" /></a></p>
<div class="definition">
<p><span class="math inline">\(n \theta = (2k - 1) \frac{\pi}{2}\)</span>, for <span class="math inline">\(k \in [1, \cdots, n]\)</span></p>
<p><span class="math inline">\(\theta = \frac{2k - 1}{2n} \pi\)</span></p>
</div>
<h1 id="piecewise-interpolation">Piecewise Interpolation</h1>
<h2 id="hermite-interpolation">Hermite Interpolation</h2>
<p>Assume we are interpolating a function <span class="math inline">\(f(x)\)</span>. We can perform nth degree Hermite interpolation at <span class="math inline">\((x_1, x_2, \cdots, x_n)\)</span> if we know <span class="math inline">\(f(x_i), f&#39;(x_i), \cdots, f^{(n)}(x_i)\)</span>.</p>
<h1 id="numerical-integration">Numerical Integration</h1>
<p>Suppose we want to integrate</p>
<p><span class="math display">\[I = \int_a^b f(x) dx\]</span></p>
<p>We can replace <span class="math inline">\(f(x)\)</span> by an interpolating polynomial and solve numerically.</p>
<p><span class="math display">\[Q = \int_a^b P_n(x) dx\]</span></p>
<p>where the error is <span class="math display">\[E = \int_a^b f(x) - P_n(x) dx\]</span></p>
<h1 id="midpoint-method">Midpoint Method</h1>
<p>Let <span class="math inline">\([a, b]\)</span> be a small interval.</p>
<p>Approximate <span class="math inline">\(f\)</span> over <span class="math inline">\([a,b]\)</span> with <span class="math inline">\(f(\frac{a+b}{2})\)</span>.</p>
<p><span class="math inline">\(Q = \int_a^b f\left( \frac{a+b}{2} \right) dx = f \left(\frac{a+b}{2} \right) (b - a)\)</span></p>
<p>This is equivalent to using an interpolating polynomial of degree 0.</p>
<p><strong>midpoint method drawing</strong></p>
<h2 id="error-2">Error</h2>
<p><span class="math inline">\(f(x) = f(m) + f&#39;(\varepsilon) \cdot (x - m) + \frac{f&#39;&#39;(\varepsilon)}{2!}(x - m)^2\)</span>, where <span class="math inline">\(\varepsilon \in [a,b]\)</span></p>
<p>The first part of the error term is</p>
<p><span class="math inline">\(\int_a^b f&#39;(m) (x - m) dx = 0\)</span></p>
<p>The second part of the error term is</p>
<p><span class="math inline">\(\text{error} = \frac{1}{2} \int_a^b f&#39;&#39;(\varepsilon) (x - m)^2 dx\)</span></p>
<p>Since <span class="math inline">\((x-m)^2\)</span> doesn't change sign, we can use the mean value theorem for integrals to conclude,</p>
<p><span class="math inline">\(\text{error} = f&#39;&#39;(\eta) \frac{1}{2} \int_a^b (x-m)^2 dx = \frac{f&#39;&#39;(\eta) (b-a)^2}{24}\)</span>, for <span class="math inline">\(\eta \in [a,b]\)</span></p>
<h3 id="mvt-for-integrals">MVT for Integrals</h3>
<p>Assume <span class="math inline">\(g(x) \in C[a,b]\)</span>. <span class="math inline">\(\phi(x)\)</span> is integrable that is nonnegative or nonpositive on <span class="math inline">\([a,b]\)</span>. Then there is a point <span class="math inline">\(\eta \in [a,b]\)</span> such that <span class="math inline">\(\int_a^b g(x) \phi(x) dx = g(\eta) \inta^b \phi(x) dx\)</span></p>
<h1 id="trapezoidal-method">Trapezoidal Method</h1>
<p>Let <span class="math inline">\([a, b]\)</span> be a small interval.</p>
<p>Approximate <span class="math inline">\(f\)</span> over <span class="math inline">\([a,b]\)</span> with <span class="math inline">\(f(a) + f[a,b](x - a)\)</span>.</p>
<p><span class="math display">\[\begin{aligned} Q &amp;= \int_a^b \left[ f(a) + f[a,b] (x - a) \right] dx \\
  &amp;= f(a)(b - a) + f[a,b] \frac{(x - a)^2}{2}_\eval{a,b} \\
  &amp;= \frac{b-a}{2} \cdot \left[ f(a) + f(b) \right] \end{aligned}\]</span></p>
<p><strong>trapezoidal method drawing</strong></p>
<h2 id="error-3">Error</h2>
<p><span class="math inline">\(f(x) = f(a) + f[a,b](x - a) + \frac{f&#39;&#39;(\varepsilon)}{2} (x-a)(x -b)\)</span></p>
<p><span class="math inline">\(\text{error} = \int_a^b \frac{f&#39;&#39;(\varepsilon)}{2} \underbrace{(x - a)}_{\geq 0}\underbrace{((x - b)}_{\leq 0}\)</span>, where <span class="math inline">\((x - a)(x - b)\)</span></p>
<p>Since <span class="math inline">\((x - a)(x - b)\)</span> is nonpositive,</p>
<p><span class="math display">\[\text{error} = \frac{f&#39;&#39;(\eta)}{2} \int_a^b (x - a)(x - b) dx = -f&#39;&#39;(\eta)}\frac{(b - a)^3}{12}\]</span></p>
<h1 id="simpsons-method">Simpson's Method</h1>
<p>Replace <span class="math inline">\(f(x)\)</span> by a 2nd order polynomial in Lagrange form.</p>
<p><span class="math display">\[Q = \int_a^b P_2(x) dx = \frac{h}{6} \left[ f(a) + 4 f(m) + f(b) \right]\]</span></p>
<h2 id="error-4">Error</h2>
<p><span class="math inline">\(\text{error} = \frac{f^{(4)}(\eta) (b - a)^5}{90 \cdot 2^5}\)</span></p>
<h1 id="degree-of-precision">Degree of Precision</h1>
<p>The degree of precision</p>
<h1 id="composite-midpoint-rule">Composite Midpoint Rule</h1>
<div class="definition">
<p><strong>Sum</strong></p>
<p><span class="math display">\[M = \frac{b - a}{n} \sum_{i=1}^n f \left( \frac{ x_i + x_{i+1}}{2} \right)\]</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>Break the polynomial into <span class="math inline">\(n\)</span> equal intervals with endpoints, <span class="math inline">\([x_1, \cdots, x_{n+1}]\)</span></p>
<p>Perform midpoint rule on each interval.</p>
<p>Assuming interval spacing of <span class="math inline">\(h\)</span>:</p>
<p><span class="math display">\[M = \frac{h}{n} \sum_{i=1}^n f \left( \frac{ x_i + x_{i+1}}{2} \right)\]</span></p>

</div>
</div>

<div class="definition">
<p><strong>Error</strong></p>
<p><span class="math display">\[\text{error} = \frac{h^2}{24}(b - a) \cdot f&#39;&#39;(\eta)\]</span></p>
<p>for <span class="math inline">\(a \leq \eta \leq b\)</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>From a previous section, the error in the midpoint rule is <span class="math inline">\(\text{error} = \frac{f&#39;&#39;(\eta)}{24} (b - a)^3\)</span></p>
<p>The error in each interval sums, so the error of the composite midpoint rule is</p>
<p><span class="math display">\[\text{error} = \left(\frac{b - a}{n} \right)^3 \sum_{i=1}^n f&#39;&#39;(\eta)/24\]</span></p>
<p>Using intermediate value theorem on <span class="math inline">\(f&#39;&#39;(x)\)</span>,</p>
<p><span class="math display">\[\text{error} = \left(\frac{(b - a)^3}{n^2} \right)^3 \sum_{i=1}^n \frac{f&#39;&#39;(\eta)/24}{n} = \left(\frac{(b - a)^3}{n^2} \right)^3 \sum_{i=1}^n \frac{f&#39;&#39;(\psi)/24}{n}\]</span></p>
<p>where <span class="math inline">\(a \leq \psi \leq b\)</span></p>
<p>So we have bounded the error.</p>

</div>
</div>

<h1 id="composite-trapezoidal-rule">Composite Trapezoidal Rule</h1>
<div class="definition">
<p><strong>Sum</strong></p>
<p><span class="math display">\[Q = \frac{h}{2} \left[ f(a) + 2 \sum_{i=1}^n f(x_i) + f(b) \right]\]</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>Break the polynomial into <span class="math inline">\(n\)</span> intervals with endpoints, <span class="math inline">\([x_1, \cdots, x_{n+1}]\)</span></p>
<p>Perform trapezoidal rule on each interval.</p>
<p>From a previous section <span class="math inline">\(Q = (b - a) \frac{f(a) + f(b)}{2}\)</span></p>
<p>Assuming equal interval spacing, <span class="math inline">\(h = (b - a)/n\)</span></p>
<p><span class="math display">\[Q = \frac{h}{2} \left[ \sum_{i=1}^n f(x_i) + f(x_{i+1}) \right] = \frac{h}{2} \left[ f(a) + 2 \sum_{i=1}^n f(x_i) + f(b) \right]\]</span></p>

</div>
</div>

<div class="definition">
<p><strong>Error</strong></p>
<p><span class="math inline">\(\text{error} = \frac{-h^2}{12}(b-a) f&#39;&#39;(n)}\)</span></p>
<p>where <span class="math inline">\(a \leq \eta \leq b\)</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>The error was previously defined as <span class="math inline">\(\text{error} = \frac{-f&#39;&#39;(\eta)}{12} (b -a)^3\)</span></p>
<p>Assuming equal interval spacing, <span class="math inline">\((b - a) = h\)</span></p>
<p><span class="math display">\[\text{error} = \frac{-h^3}{12} \sum_{i=1}^{n} f&#39;&#39;(n_i) = \frac{-h^2}{12}(b-a) \underbrace{\frac{1}{n} \sum_{i=1}^{n} f&#39;&#39;(n_i)}_{\text{IVT}} = \frac{-h^2}{12}(b-a) f&#39;&#39;(n)}\]</span></p>
<p>where <span class="math inline">\(a \leq \eta \leq b\)</span></p>

</div>
</div>

<h1 id="composite-simpsons-rule">Composite Simpson's Rule</h1>
<div class="definition">
<p><strong>Sum</strong></p>
<p>Assume equal subintervals with endpoints <span class="math inline">\([x_1, \cdots, x_{n+1}]\)</span></p>
<p><span class="math display">\[S = \frac{h}{3} \left[ f(x_1) + 4 \sum_{i=2,4, ...}^n f(x_i) + 2 \sum_{i=3,5, ...}^n f(x_i) + f(x_{n+1}) \right]\]</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>We had previously <span class="math inline">\(S = \frac{h}{b} \left[ f(a) + 4 f(m) + f(b) \right]\)</span></p>
<p>Since each interval contains 3 points, the interval is twice as long as before: <span class="math inline">\(2h\)</span></p>
<p><span class="math display">\[\begin{aligned}S &amp;= \frac{2h}{6} \left[ f(x_1) + 4 f(x_2) + f(x_3) + f(x_3) + 4 f(x_4) + f(x_5) + \cdots + f(x_{n-1}) + 4 f(x_n) + f(x_{n+1}) \right] \\
&amp;= \frac{h}{3} \left[ f(x_1) + 4 \sum_{i=2,4, ...}^n f(x_i) + 2 \sum_{i=3,5, ...}^n f(x_i) + f(x_{n+1}) \right] \end{aligned}\]</span></p>

</div>
</div>

<div class="definition">
<p><strong>Error</strong></p>
<p><span class="math display">\[\text{error} = \frac{h^4}{180}(b - a) f^{(4)}(\psi)\]</span></p>
<p>where <span class="math inline">\(a \leq \psi \leq b\)</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>Previously, the error was <span class="math inline">\(\text{error} = \left( \frac{b - a}{2} \right)^5 \frac{f^{(4)}(\eta)}{90}\)</span></p>
<p>Since the interval is now twice as large, <span class="math inline">\((b - a) = 2h\)</span>, the error for a single interval is</p>
<p><span class="math inline">\(\text{error} = h^5 \frac{f^{(4)}(\eta)}{90}\)</span></p>
<p>Since the error sums,</p>
<p><span class="math inline">\(\text{error} = \frac{h^5}{90} \sum_{i=1}^{n/2} f^{(4)}(\eta_i)\)</span></p>
<p>Using intermediate value theorem</p>
<p><span class="math display">\[\text{error} = \frac{h^4}{90}(b - a) \frac{1}{2} \underbrace{\frac{1}{n/2} \sum_{i=1}^{n/2} f^{(4)}(\eta_i)}_\text{IVT} = \frac{h^4}{180}(b - a) f^{(4)}(\psi)\]</span></p>
<p>where <span class="math inline">\(a \leq \psi \leq b\)</span></p>

</div>
</div>

<h1 id="gaussian-quadrature">Gaussian Quadrature</h1>
<p>Assume we are computing <span class="math inline">\(I = \int_{-1}^1 f(x) dx\)</span>. With Gaussian quadrature method, we use carefully chosen points <span class="math inline">\([x_1, \cdots, x_{n+1}] \in [-1, 1]\)</span> to make the integral precision as high as possible.</p>
<p>We begin by defining a family of orthogonal polynomials known as Legendre polynomials</p>
<div class="definition">
<p><strong>Legendre polynomial</strong></p>
<p><span class="math inline">\(P_0(x) = 1\)</span></p>
<p><span class="math inline">\(P_1(x) = x\)</span></p>
<p><span class="math inline">\(P_2(x) = \frac{1}{2}(3x^2 - 1)\)</span></p>
<p><span class="math inline">\(P_3(x) = \frac{1}{2} (5x^3 - 3x)\)</span></p>
<p><span class="math inline">\(P_4(x) = \frac{1}{8}(35x^4 - 30x^2 + 3)\)</span></p>
<p><span class="math inline">\(P_5(x) = \frac{1}{8}(63x^5 - 70x^3 + 15x)\)</span></p>
<p><span class="math display">\[P_{j+1}(x) = \frac{2j + 1}{j+1} x P_j(x) - \frac{j}{j+1} P_{j-1}(x)\]</span></p>
<p>These polynomials have the following properties:</p>
<ul>
<li>j is odd -&gt; <span class="math inline">\(P_j\)</span> is even</li>
<li>j is even -&gt; <span class="math inline">\(P_j\)</span> is odd</li>
<li><span class="math inline">\(P_j(1) = 1\)</span></li>
<li><span class="math inline">\(\int_{-1}^1 P_k(x) x^j dx = 0\)</span> for <span class="math inline">\(j = 0, \cdots, k-1\)</span></li>
</ul>
</div>
<p>We use the roots of <span class="math inline">\(P_k(x)\)</span> as the interpolation points for quadratic interpolation.</p>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p><span class="math inline">\(P_3(x) = \frac{1}{2}(5x^3 - 3x)\)</span></p>
<p><span class="math inline">\(G(f) = w_1 f(x_1) + w_2 f(x_2) + w_3 f(x_3)\)</span></p>
<p>Let <strong>f = 1</strong></p>
<p><span class="math inline">\(\int_{-1}^1 1 dx = 2 = w_1 \cdot 1 + w_2 \cdot 1 + w_3 \cdot 1\)</span></p>
<p>Let <strong>f = x</strong></p>
<p><span class="math inline">\(\int_{-1}^1 x dx = 0 = w_1 \cdot (- \sqrt{\frac{3}{5}}) + w_2 \cdot 0 + w_3 \cdot \sqrt{\frac{3}{5}}\)</span></p>
<p>Let <strong>f = x<sup>2</sup></strong></p>
<p><span class="math inline">\(\int_{-1}^1 x^2 dx = \frac{2}{3} = w_1 \cdot (\frac{3}{5}) + w_2 \cdot 0 + w_3 \cdot (\frac{3}{5})\)</span></p>
<p>Solving the resultant system, we get <span class="math inline">\(w_1 = w_3 = \frac{5}{9}, w_2 = \frac{8}{9}\)</span></p>
<p><span class="math inline">\(G(f) = \frac{5}{9} f(- \sqrt{\frac{5}{9}}) + \frac{8}{9} f(0) + \frac{5}{9} f(\sqrt{\frac{5}{9}})\)</span></p>
<p>If <span class="math inline">\(f(x) = x^4\)</span>, <span class="math inline">\(\int_{-1}^1 x^4 dx = \frac{2}{5}\)</span></p>
<p><span class="math display">\[G(f) = \frac{5}{9} (- \sqrt{\frac{5}{9}})^4 + \frac{8}{9} (0)^4 + \frac{5}{9} (\sqrt{\frac{5}{9}})^4 = \frac{2}{5}\]</span></p>
<p>If <span class="math inline">\(f(x) = x^5\)</span>, <span class="math inline">\(\int_{-1}^1 x^5 dx = 0\)</span></p>
<p><span class="math display">\[G(f) = 0\]</span></p>
<p>So here, the approximation <span class="math inline">\(G(f)\)</span> works for polynomials up to degree 5.</p>

</div>
</div>


<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p><strong>Error</strong></p>
<p>Given <span class="math inline">\(n+1\)</span> Gaussian interpolation points, <span class="math inline">\([x_1, \cdots, x_{n+1}] \in [-1, 1]\)</span></p>
<p>the error <span class="math display">\[\int_{-1}^1 \underbrace{f(x) - \phi_n(x)}_{E_n(x)} dx\]</span></p>
<p><span class="math inline">\(E_n(x) = f(x) - \phi_n(x) = \frac{f^{(n+1)}(\zeta(x))}{(n+1)!}(x - x_1)(x - x_2) \cdots (x - x_{n+1}) = f[x_1, \underbrace{f_x, \cdots, x_{n+1}}_\text{n+1 points}, x]\)</span></p>
<p>So the error <span class="math display">\[\int_{-1}^1 \underbrace{f(x) - \phi_n(x)}_{E_n(x)} dx = \int_{-1}^1 \frac{f^{(n+1)}(\zeta(x))}{(n+1)!} \underbrace{P(x - x_1) \cdots (x - x_{n+1})}_\text{Legendre polynomial} = 0\]</span></p>
<p>if $f<sup>(n+1)</sup>(x) is a polynomial of degree less than n.</p>
<p>So if <span class="math inline">\(f\)</span> is a polynomial of degree less than 2n + 1, then the Gaussian quadrature interpolation method will have error 0.</p>

</div>
</div>

<h1 id="approximating-functions">Approximating Functions</h1>
<div class="definition">
<p>Given a function <span class="math inline">\(f\)</span> on an interval <span class="math inline">\([a, b]\)</span> and a set of basis functions, <span class="math inline">\(\phi_j\)</span> for <span class="math inline">\(j \in 0 \cdots n\)</span>,</p>
<p>we try to find an approximation <span class="math display">\[v(x) = \sum_{j=0}^n c_j \phi_j (x)\]</span></p>
<p>such that the following quantity is minimized</p>
<p><span class="math display">\[\int_1^b [f(x) - v(x) ]^2 dx = || f - v ||_2^2\]</span></p>
<p>We denote the minimizing <span class="math inline">\(v\)</span> as <span class="math inline">\(v^* = \sum_0^n c_j^* \phi_j(x)\)</span></p>
</div>
<p><span class="math display">\[min ||f - v||_2^2 = \int_a^b \left( f(x - \sum_{j=0}^{n+1} c_j \phi_j(x) \right)^2 dx\]</span></p>
<p>Differentiate with respect to <span class="math inline">\(c_k\)</span></p>
<p><span class="math display">\[\frac{d}{dk} \int_a^b \left( f(x - \sum_{j=0}^{n+1} c_j \phi_j(x) \right)^2 dx = 2 \int_a^b \left( f(x - \sum_{j=0}^{n} c_j \phi_j(x) \right) ( - \phi_k(x) ) dx = 0\]</span></p>
<p><span class="math display">\[\int_a^b f(x)(- \phi_k(x)) dx = \int_a^b \sum_{j=0}^{n} \ c_j phi_j(x) \phi_k(x) dx = \sum_{j=0}^n c_j \int_a^b \phi_j(x) \phi_k(x) dx\]</span></p>
<p>so</p>
<p><span class="math display">\[\underbrace{\sum_{j=0}^n c_j \int_a^b \phi_j(x) \phi_k(x) dx}_{\sum_{j=0}^n c_j B_{kj}} = \underbrace{\int_a^b f(x)(- \phi_k(x)) dx}_{b_k}\]</span></p>
<p>If we choose the monomial basis,</p>
<p><span class="math inline">\(c_i = \frac{b_i}{B_{ii}}\)</span></p>
<p>where <span class="math inline">\(b_i = \int_a^b w(x) f (x) \phi_i(x) dx\)</span></p>
<div class="examples">
<p>Let the basis functions be the Legendre polynomials</p>
<p><span class="math inline">\(\phi_0 = 1\)</span>, <span class="math inline">\(\phi_1 = x\)</span>, <span class="math inline">\(\phi_2 = \frac{1}{2}(3x^2 - 1)\)</span></p>
<p>If we are minimizing <span class="math inline">\(||f - v(x) ||_2^2\)</span></p>
<p>then <span class="math inline">\(v^*(x) = \frac{e - e^{-1}}{2} + 3e^{-1}x + \frac{5}{2}(e - 7e^{-1}) \frac{1}{2}(3x^2 - 1)\)</span></p>
<p><span class="math inline">\(c_1 = \frac{b1}{B_{11}}\)</span>, <span class="math inline">\(b_1 = \int_{-1}^1 e^x \phi_1(x) d = 2e^{-1}\)</span>, <span class="math inline">\(B_{11} = \frac{2}{3}\)</span></p>
<p><span class="math inline">\(c_2 = \frac{b2}{B_{22}}\)</span>, <span class="math inline">\(b_2 = \int_{-1}^1 e^x \phi_2(x) d = e - 7e^{-1}\)</span>, <span class="math inline">\(B_{22} = \int_{-1}^1 \left(\frac{1}{2}(3x^2 - 1) \right)^2 dx = \frac{2}{5}\)</span></p>
</div>
<h2 id="properties-of-norms">Properties of Norms</h2>
<ol>
<li><p><span class="math inline">\(|| g || \geq 0\)</span>, <span class="math inline">\(||g|| = 0 \Rightarrow g(x) = 0\)</span> on <span class="math inline">\([a,b]\)</span></p></li>
<li><p><span class="math inline">\(||\alpha g|| = |\alpha|||g||\)</span></p></li>
<li><p><span class="math inline">\(||f + g||_2^2 \leq \left( ||f||_2 + ||g||_2 \right)^2\)</span></p></li>
</ol>
<h2 id="least-squares">Least Squares</h2>
<p><span class="math display">\[Va \approx y\]</span></p>
<p>We can get the residual error by $r = y - Va<span class="math display">\[

   Since $Va^*$ is a projection of $y$ to a lower dimension, $r$ is orthogonal to $Va^*$ and therefore $V^T$.

   $V^T(y - Va^*) = 0 \Longrightarrow V^Ty = V^TVa$

** Orthogonal Polynomials
   $\phi_{-1} = 0$

   $\phi_0 = 1$

   \]</span><em>ϕ</em><sub>j</sub>(x) - x <em>ϕ</em><sub>j-1</sub>(x) = b <em>ϕ</em><sub>j-1</sub> - c <em>ϕ</em><sub>j</sub>-1} + d ∑<sub>k=0</sub><sup>j-3</sup><span class="math display">\[

   three term recurrence relation: $\phi_j(x) = (x - b_j) \phi_{j-1}(x) - c_j \phi_{j-2}(x)$

   $(\phi_j, \phi_{j-1}) = 0 = (x \phi_{j-1}, \phi_{j-1}) - \b_j (\phi_{j-1}, \phi_{j-1}) - c_j (\phi_{j-2}, \phi_{j-1})$ 

   Multiply by $\phi_{j-1}$, integrate from a to b with weight for $w$ to find $b_j$

   \]</span>b<sub>j</sub> =  = <span class="math display">\[

   Repeat with $\phi_{j-2}$ to find $c_j$

   \]</span>c<sub>j</sub> = <span class="math display">\[

** Legendre Polynomial

   $w(x) = $

   $\phi_1(x) = (x - b_1) \phi_0 - c_1 \phi_{-1} = (x - b_1) 1 - c_1 0 = x - b_1$

   From our earlier results,
   
   \]</span>b<sub>j</sub> =  = <span class="math display">\[

   \]</span>c<sub>2</sub> =  =  =  = 1/3<span class="math display">\[

   \]</span><em>ϕ</em><sub>2</sub> = x<sup>2</sup> - 1/3<span class="math display">\[

*** Orthogonality

    \]</span>P<sub>n</sub>(x) =   (1 - x<sup>2</sup>)<sup>n</sup><span class="math display">\[

    $P_0(x) = 0$, $P_1(x) = 1$

    We will show $\int_{-1}^1 P_j(x) P_k(x) dx = 0$ where $j &lt; k$

    \]</span>∫<sub>-1</sub><sup>1</sup>  (1 - x<sup>2</sup>)<sup>j</sup> ⋅  (1 - x<sup>2</sup>)<sup>k</sup> dx</p>
<h2 id="chebyshev-polynomial">Chebyshev Polynomial</h2>
<p>Family of orthogonal polynomials on the interval <span class="math inline">\([-1, 1]\)</span> with weights <span class="math inline">\(w(x) = \frac{1}{\sqrt{1 - x^2}}\)</span>.</p>
<p>i.e. the weights approach infinity when <span class="math inline">\(x \rightarrow \pm 1\)</span>, which puts more weight at the ends of the interval.</p>
<div class="definition">
<p><span class="math inline">\(\phi_0 = 1\)</span>, <span class="math inline">\(\phi_1 = x\)</span>, <span class="math inline">\(\phi_j = (x - b_j) \phi_{j-1} - c_j \phi_{j - 2}\)</span></p>
<p><span class="math inline">\(\phi_2 = x^2 - 1/2\)</span>, <span class="math inline">\(\phi_3 = x^3 - 3/4\)</span>, <span class="math inline">\(\phi_4 = x^4 - x^2 + 1/8\)</span></p>
</div>
<h3 id="alternative-representation">Alternative Representation</h3>
<p><span class="math inline">\(T_j = \cos(j \arccos(x)) = \cos(j \theta)\)</span>, where <span class="math inline">\(\theta = \arccos(x)\)</span> ⇒ <span class="math inline">\(\cos(\theta) = x\)</span></p>
<p>which has roots <span class="math inline">\(j \theta = (2k - 1) \frac{\pi}{2} \Rightarrow \theta_k = \frac{2k - 1}{j} \frac{\pi}{2}\)</span> for <span class="math inline">\(k = 1,2, \cdots, j\)</span></p>
<div class="examples">
<p>Notice that <span class="math inline">\(T_j\)</span> has the same roots as <span class="math inline">\(\phi_j\)</span>, but scaled.</p>
<p><span class="math inline">\(T_2 = 2x^2 - 1\)</span> <span class="math inline">\(\phi_2 = x^2 - 1/2\)</span></p>
</div>
<p>The function has extreme points at <span class="math inline">\(\cos(j \theta) = \pm1 \Rightarrow \theta = \frac{k \pi}{j}\)</span></p>
<p><span class="math inline">\(T_j = \cos(j \theta)\)</span></p>
<p><span class="math inline">\(T_{j+1} = \cos((j + 1) \theta) = \cos(j\theta + \theta) = \cos(j \theta) \cos( \theta) - sin(\j \theta) \sin(\theta)\)</span></p>
<p><span class="math inline">\(T_{j-1} = \cos((j - 1) \theta = \cos(j \theta - \theta) = \cos(j \theta) \cos( \theta) + sin(j \theta)\sin(\theta)\)</span></p>
<p><span class="math inline">\(T_{j+1} + T_{j - 1} = 2 \cos(j \theta) \cos(\theta) = 2 T_j (\theta) \cdot x = 2x t_j(x) - T_{j-1}(x)\)</span></p>
<p><span class="math inline">\(T_0 = 1\)</span></p>
<p><span class="math inline">\(T_1 = x\)</span></p>
<p><span class="math inline">\(T_2 = 2x^2 - 1\)</span></p>
<p><span class="math inline">\(T_3 = 2x(2x^2 - 1) - x = 4x^3 - 3x\)</span></p>
<p><span class="math inline">\(\phi_j = \prod_{k=1}^j (x - \cos(\theta_k))\)</span> for <span class="math inline">\(\theta_k = \frac{2k - 1}{j} \frac{\pi}{2}\)</span></p>
<p><span class="math inline">\(\phi_j = \frac{1}{2^{j-1}} T_j(x)\)</span></p>
<div class="theorem">
<p>The minimum of <span class="math inline">\(max_{-1 \leq x \leq 1} |P_n(x)\)</span> is <span class="math inline">\(max_{-1 \leq x \leq 1} |\phi_n(x)| = \frac{1}{2^{n-1}}\)</span></p>
</div>

<div class="derivation" onclick="showHide(this);">
<div>
Proof
</div>
<div class="proof latex" style="display:none;">

<p>Assume there is a monic polynomial such that <span class="math inline">\(max_{-1 \leq x \leq 1} |P_n(x)| &lt; \frac{1}{2^{n-1}}\)</span></p>
<p>Consider the polynomial <span class="math inline">\(q = \phi_n(x) - P_n(x)\)</span> (degree less than n - 1, since leading <span class="math inline">\(x^n\)</span> cancels)</p>
<p>Consider n+1 extreme points of <span class="math inline">\(\phi_n(x)\)</span></p>
<p><span class="math inline">\(r_k = \frac{k \pi}{n}\)</span> for k = 0,1,…,n</p>
<p><span class="math inline">\(q(r_k) = \phi_n(r_k) - P_n(r_k) = \pm \frac{1}{2^{n-1}} - P_n(r_k)\)</span></p>
<p><strong>even points</strong></p>
<p><span class="math inline">\(q(r_k) = \frac{1}{2^{n-1} - P_n(r_k) \geq 0\)</span></p>
<p><strong>odd points</strong></p>
<p><span class="math inline">\(q(r_k) = \frac{-1}{2^{n-1} - P_n(r_k) \leq 0\)</span></p>
<p>There are <span class="math inline">\(n\)</span> changes of sign between even and odd points</p>

</div>
</div>

<h1 id="todo">todo</h1>
<ul>
<li>algo vs problem</li>
<li>problem conditioning</li>
<li>backwards stability</li>
<li>find k of integration prob</li>
<li>types of convergence
<ul>
<li>linear</li>
<li>quadratic</li>
<li>forbinius</li>
<li>3.5</li>
</ul></li>
<li>hessian matrix</li>
<li>read chapter 10</li>
<li>review parabolic interpolation</li>
<li><p>piecewise polynomial interpolation</p></li>
<li><p>chebyshev polynomial ch12</p></li>
<li><p>everything up to piecewise polynomial interpolation</p></li>
<li><p>read chebyshev polynomial 10.6</p></li>
</ul>
				</div>
			</div>
		</div>
	</div>
</body>
</html>
